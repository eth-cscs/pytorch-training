{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2363679-29a4-402d-bc2c-9cd31fe0944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.tfrecord as tfrec\n",
    "from torchvision import models\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "from nvidia.dali.plugin.pytorch import DALIClassificationIterator, LastBatchPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab170ac-62d3-460d-bf88-aa4da966cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/scratch/snx3000/datasets/imagenet/ILSVRC2012_1k/'\n",
    "\n",
    "tfrec_files = sorted(glob.glob(f'{data_dir}/train/*'))\n",
    "index_files = sorted(glob.glob(f'{data_dir}/idx_files/train/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510ac1a-ede0-4718-9c03-bd8a6701a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "pipe = Pipeline(batch_size=batch_size,\n",
    "                num_threads=12,\n",
    "                device_id=None)\n",
    "\n",
    "with pipe:\n",
    "    inputs = fn.readers.tfrecord(\n",
    "        path=tfrec_files,\n",
    "        index_path=index_files,\n",
    "        features={\n",
    "            'image/encoded': tfrec.FixedLenFeature((), tfrec.string, \"\"),\n",
    "            'image/class/label': tfrec.FixedLenFeature([1], tfrec.int64,  -1),\n",
    "        }\n",
    "    )\n",
    "    jpegs = inputs[\"image/encoded\"]\n",
    "    labels = inputs[\"image/class/label\"][0] - 1\n",
    "    images = fn.decoders.image(jpegs, device='cpu', output_type=types.RGB)\n",
    "    resized = fn.resize(images, device='cpu', size=(224, 224))\n",
    "    output = fn.crop_mirror_normalize(\n",
    "        resized,\n",
    "        dtype=types.FLOAT,\n",
    "        mean=[0., 0., 0.],\n",
    "        std=[1., 1., 1.]\n",
    "    )\n",
    "    pipe.set_outputs(output, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7121c479-e47f-498a-bf93-bc2bcceb77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed224b6-fc13-4472-968b-fe1954ab2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DALIClassificationIterator(\n",
    "    pipe,\n",
    "    last_batch_padded=False,\n",
    "    auto_reset=True,\n",
    "    last_batch_policy=LastBatchPolicy.DROP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd1a310-7d59-44ea-be87-926f318c983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "\n",
    "model = models.resnet50()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8706059-a638-4416-98dd-be9f91f0003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55873c-a2ac-4e31-b0ec-f7ef4d8ad4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_step(model, imgs, labels):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(imgs)\n",
    "    loss = F.cross_entropy(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51853a-dffa-437d-9656-d739429820a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "num_iters = 10\n",
    "imgs_sec = []\n",
    "for epoch in range(num_epochs):\n",
    "    t0 = time.time()\n",
    "    for step, samples in enumerate(train_loader):\n",
    "        if step > num_iters:\n",
    "            break\n",
    "        \n",
    "        imgs = samples[0]['data']\n",
    "        labels = samples[0]['label']\n",
    "        benchmark_step(model,\n",
    "                       imgs.to(device),\n",
    "                       labels.to(device))\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    imgs_sec.append(batch_size * num_iters / dt)\n",
    "\n",
    "    print(f' * Epoch {epoch:2d}: '\n",
    "          f'{imgs_sec[epoch]:.2f} images/sec per GPU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpcpython2022",
   "language": "python",
   "name": "hpcpython2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
