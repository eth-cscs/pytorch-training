{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3871ef15-6502-4a21-a3eb-5be0e3dfd82d",
   "metadata": {},
   "source": [
    "# Basic training of a CNN on imagenet from tfrecord files using NVidia DALI\n",
    "\n",
    "Here we will run a simplified training loop for a CNN model on ImageNet. We will create an [NVidia DALI](https://docs.nvidia.com/deeplearning/dali/user-guide/docs/index.html) input pipeline based on the [tfrecord](https://docs.nvidia.com/deeplearning/dali/user-guide/docs/operations/nvidia.dali.fn.readers.tfrecord.html#nvidia-dali-fn-readers-tfrecord) reader to read the ImageNet dataset stored in tfrecord files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2363679-29a4-402d-bc2c-9cd31fe0944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.tfrecord as tfrec\n",
    "from torchvision import models\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "from nvidia.dali.plugin.pytorch import DALIClassificationIterator, LastBatchPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab170ac-62d3-460d-bf88-aa4da966cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/scratch/snx3000/datasets/imagenet/ILSVRC2012_1k/'\n",
    "\n",
    "tfrec_files = sorted(glob.glob(f'{data_dir}/train/*'))\n",
    "index_files = sorted(glob.glob(f'{data_dir}/idx_files/train/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bccff2-2673-47c8-b3e4-e0eab3929522",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "pipe = Pipeline(batch_size=batch_size,\n",
    "                num_threads=12,\n",
    "                device_id=None)\n",
    "\n",
    "with pipe:\n",
    "    example = fn.readers.tfrecord(\n",
    "        path=tfrec_files,\n",
    "        index_path=index_files,\n",
    "        features={\n",
    "            'image/encoded': tfrec.FixedLenFeature((), tfrec.string, ''),\n",
    "            'image/class/label': tfrec.FixedLenFeature((), tfrec.int64, -1),\n",
    "        }\n",
    "    )\n",
    "    label = example['image/class/label'] - 1\n",
    "    image = fn.decoders.image(example['image/encoded'], device='cpu', output_type=types.RGB)\n",
    "    image = fn.resize(image, device='cpu', size=(224, 224), dtype=types.FLOAT)\n",
    "    image = fn.transpose(image, perm=(2, 0, 1))\n",
    "    pipe.set_outputs(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7121c479-e47f-498a-bf93-bc2bcceb77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed224b6-fc13-4472-968b-fe1954ab2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DALIClassificationIterator(\n",
    "    pipe,\n",
    "    last_batch_padded=False,\n",
    "    auto_reset=True,\n",
    "    last_batch_policy=LastBatchPolicy.DROP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd1a310-7d59-44ea-be87-926f318c983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "\n",
    "model = models.resnet50()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8706059-a638-4416-98dd-be9f91f0003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55873c-a2ac-4e31-b0ec-f7ef4d8ad4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_step(model, imgs, labels):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(imgs)\n",
    "    loss = F.cross_entropy(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51853a-dffa-437d-9656-d739429820a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "num_iters = 10\n",
    "imgs_sec = []\n",
    "for epoch in range(num_epochs):\n",
    "    t0 = time.time()\n",
    "    for step, samples in enumerate(train_loader):\n",
    "        if step > num_iters:\n",
    "            break\n",
    "        \n",
    "        imgs = samples[0]['data']\n",
    "        labels = samples[0]['label']\n",
    "        benchmark_step(model,\n",
    "                       imgs.to(device),\n",
    "                       labels.to(device))\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    imgs_sec.append(batch_size * num_iters / dt)\n",
    "\n",
    "    print(f' * Epoch {epoch:2d}: '\n",
    "          f'{imgs_sec[epoch]:.2f} images/sec per GPU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2022",
   "language": "python",
   "name": "pytorch2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
