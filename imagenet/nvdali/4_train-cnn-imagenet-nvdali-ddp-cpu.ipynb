{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c23c980-dceb-4d20-bc82-bce5afc1744b",
   "metadata": {},
   "source": [
    "# Basic training on multiple GPUs of a CNN on imagenet from tfrecord files using NVidia DALI\n",
    "\n",
    "Here we will run a simplified training loop for a CNN model on ImageNet. We will create an [NVidia DALI](https://docs.nvidia.com/deeplearning/dali/user-guide/docs/index.html) input pipeline based on the [tfrecord](https://docs.nvidia.com/deeplearning/dali/user-guide/docs/operations/nvidia.dali.fn.readers.tfrecord.html#nvidia-dali-fn-readers-tfrecord) reader to read the ImageNet dataset stored in tfrecord files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a65790f-2ce9-4200-a3c8-2f386f4ba7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipcmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548c9d66-a697-4c43-beb6-de3910d395da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ipcluster start -n 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521b835-1b25-4fb6-8a2a-df2e6d0d92f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pxconfig --progress-after -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2363679-29a4-402d-bc2c-9cd31fe0944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributed as dist\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.tfrecord as tfrec\n",
    "from torchvision import models\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "from nvidia.dali.plugin.pytorch import DALIClassificationIterator, LastBatchPolicy\n",
    "from pt_distr_env import DistributedEnviron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab170ac-62d3-460d-bf88-aa4da966cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "data_dir = '/scratch/snx3000/datasets/imagenet/ILSVRC2012_1k/'\n",
    "\n",
    "tfrec_files = sorted(glob.glob(f'{data_dir}/train/*'))\n",
    "index_files = sorted(glob.glob(f'{data_dir}/idx_files/train/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0dd9be-a18a-4bbe-80cf-b472274e3072",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "distr_env = DistributedEnviron()\n",
    "dist.init_process_group(backend=\"nccl\")\n",
    "world_size = dist.get_world_size()\n",
    "rank = dist.get_rank()\n",
    "device = distr_env.local_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e97b9ce-858a-4645-9306-0ac0fa7ae619",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "batch_size = 128\n",
    "\n",
    "pipe = Pipeline(batch_size=batch_size,\n",
    "                num_threads=12,\n",
    "                device_id=None)\n",
    "\n",
    "with pipe:\n",
    "    example = fn.readers.tfrecord(\n",
    "        path=tfrec_files,\n",
    "        index_path=index_files,\n",
    "        features={\n",
    "            'image/encoded': tfrec.FixedLenFeature((), tfrec.string, ''),\n",
    "            'image/class/label': tfrec.FixedLenFeature((), tfrec.int64, -1),\n",
    "        },\n",
    "        shard_id=rank,\n",
    "        num_shards=world_size,\n",
    "    )\n",
    "    label = example['image/class/label'] - 1\n",
    "    image = fn.decoders.image(example['image/encoded'], device='cpu', output_type=types.RGB)\n",
    "    image = fn.resize(image, device='cpu', size=(224, 224), dtype=types.FLOAT)\n",
    "    image = fn.transpose(image, perm=(2, 0, 1))\n",
    "    pipe.set_outputs(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7121c479-e47f-498a-bf93-bc2bcceb77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "pipe.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed224b6-fc13-4472-968b-fe1954ab2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "train_loader = DALIClassificationIterator(\n",
    "    pipe,\n",
    "    last_batch_padded=False,\n",
    "    auto_reset=True,\n",
    "    last_batch_policy=LastBatchPolicy.DROP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd1a310-7d59-44ea-be87-926f318c983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "_model = models.resnet50()\n",
    "_model.to(device);\n",
    "\n",
    "ddp_model = DistributedDataParallel(_model, device_ids=[device])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8706059-a638-4416-98dd-be9f91f0003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "optimizer = optim.SGD(ddp_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55873c-a2ac-4e31-b0ec-f7ef4d8ad4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "def benchmark_step(model, imgs, labels):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(imgs)\n",
    "    loss = F.cross_entropy(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51853a-dffa-437d-9656-d739429820a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "print()\n",
    "num_epochs = 5\n",
    "num_iters = 10\n",
    "imgs_sec = []\n",
    "for epoch in range(num_epochs):\n",
    "    t0 = time.time()\n",
    "    for step, samples in enumerate(train_loader):\n",
    "        if step > num_iters:\n",
    "            break\n",
    "        \n",
    "        imgs = samples[0]['data'].to(device)\n",
    "        labels = samples[0]['label'].to(device)\n",
    "        benchmark_step(ddp_model, imgs, labels)\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    imgs_sec.append(batch_size * num_iters / dt)\n",
    "\n",
    "    print(f' * Epoch {epoch:2d}: '\n",
    "          f'{imgs_sec[epoch]:.2f} images/sec per GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df98ca8-35b9-4094-ac73-e7a9e662c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ipcluster stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2022",
   "language": "python",
   "name": "pytorch2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
