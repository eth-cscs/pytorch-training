{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380478ca-79e3-49a0-8676-ee8cf2dea112",
   "metadata": {},
   "source": [
    "# Sinusoidal Positional Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9a343-af66-40c2-bbb2-ae0473c41e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers import T5ForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd3506-1e3c-4cf0-8663-e000df0a6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 't5-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d8daa-9f35-485e-b07b-c8e62060640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "config = AutoConfig.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3147328-b365-4900-a83e-632286fb210a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96b7b9-8904-49cf-b7b0-05c98ea0833d",
   "metadata": {},
   "source": [
    "**No positional embeddings!** t5 uses sinusoidal positional encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4824ec-e40b-479b-9d33-41e50acfd73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_positional_encoding(max_len, d_model):\n",
    "    position = torch.arange(0, max_len)[:, None]\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2) * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "    pos_enc = torch.zeros((max_len, d_model))\n",
    "\n",
    "    pos_enc[:, 0::2] = torch.sin(position * div_term)\n",
    "    pos_enc[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    return pos_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043327bd-638f-4de5-9f76-de50edf7fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.max_position_embeddings = config.task_specific_params['translation_en_to_de']['max_length']\n",
    "config.hidden_size = config.d_model\n",
    "\n",
    "sin_pos_encoding = generate_positional_encoding(config.max_position_embeddings, config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89560c6a-1d28-4a14-a140-906123099232",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (12, 1)\n",
    "\n",
    "for i in [0, 1, 2, 10, 50, 100, 150, 200, 250, 299]:\n",
    "    plt.plot(sin_pos_encoding[i], alpha=0.5, c='blue')\n",
    "    plt.xlim([0, config.hidden_size])\n",
    "    plt.ylim([-1.5, 1.5])\n",
    "    plt.show()\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db19ae-f78e-4fdc-a280-49ef2ba05e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sin_pos_encoding, cmap='Blues')\n",
    "plt.xlabel('Embedding Dimensions')\n",
    "plt.ylabel('Position in Sequence')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887e484c-3ca7-4a5d-8dc6-78a6d99eca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(sin_pos_encoding)\n",
    "plt.imshow(similarity_matrix, cmap='Blues')  #, aspect='auto', extent=[0, max_len, 0, max_len])\n",
    "# plt.colorbar()\n",
    "# plt.title('Position-wise Similarity of Positional Embeddings')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Position')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2024",
   "language": "python",
   "name": "ml2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
