{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding how the SQuAD dataset is set up for our task with BERT\n",
    "\n",
    "We are going to fine-tune [BERT implemented by HuggingFace](https://huggingface.co/bert-base-uncased) for the text-extraction task with a dataset of questions and answers with the [SQuAD (The Stanford Question Answering Dataset)](https://rajpurkar.github.io/SQuAD-explorer/) dataset.\n",
    "The data is composed by a set of questions and corresponding paragraphs that contains the answers.\n",
    "The model will be trained to locate the answer in the context by giving the positions where the answer starts and ends.\n",
    "\n",
    "In this notebook we are going to see how the data is set up for training.\n",
    "\n",
    "This notebook is based on [BERT (from HuggingFace Transformers) for Text Extraction](https://keras.io/examples/nlp/text_extraction_with_bert/).\n",
    "\n",
    "More info:\n",
    "- [Glossary - HuggingFace docs](https://huggingface.co/transformers/glossary.html#model-inputs)\n",
    "- [BERT NLP — How To Build a Question Answering Bot](https://towardsdatascience.com/bert-nlp-how-to-build-a-question-answering-bot-98b1d1594d7b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import dataset_utils as du\n",
    "from transformers import BertTokenizer\n",
    "from tokenizers import BertWordPieceTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cache = os.path.join(os.getcwd(), 'cache')\n",
    "\n",
    "train_path = os.path.join(bert_cache, 'data', 'train-v1.1.json')\n",
    "eval_path = os.path.join(bert_cache, 'data', 'dev-v1.1.json')\n",
    "with open(train_path) as f:\n",
    "    raw_train_data = json.load(f)\n",
    "\n",
    "with open(eval_path) as f:\n",
    "    raw_eval_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'version'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 442 contexts for training\n",
      "- 48 contexts for testing\n"
     ]
    }
   ],
   "source": [
    "print(f\"- {len(raw_train_data['data'])} contexts for training\")\n",
    "print(f\"- {len(raw_eval_data['data'])} contexts for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alps'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_data['data'][91]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_train_data['data'][91]['paragraphs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Alps (/ælps/; Italian: Alpi [ˈalpi]; French: Alpes [alp]; German: Alpen [ˈʔalpm̩]; Slovene: Alpe [ˈáːlpɛ]) are the highest and most extensive mountain range system that lies entirely in Europe, stretching approximately 1,200 kilometres (750 mi) across eight Alpine countries: Austria, France, Germany, Italy, Liechtenstein, Monaco, Slovenia, and Switzerland. The Caucasus Mountains are higher, and the Urals longer, but both lie partly in Asia. The mountains were formed over tens of millions of years as the African and Eurasian tectonic plates collided. Extreme shortening caused by the event resulted in marine sedimentary rocks rising by thrusting and folding into high mountain peaks such as Mont Blanc and the Matterhorn. Mont Blanc spans the French–Italian border, and at 4,810 m (15,781 ft) is the highest mountain in the Alps. The Alpine region area contains about a hundred peaks higher than 4,000 m (13,123 ft), known as the \"four-thousanders\".'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_data['data'][91]['paragraphs'][0]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answers': [{'answer_start': 190, 'text': 'Europe'}],\n",
       "  'question': 'What Country are the Alps located in?',\n",
       "  'id': '56f81f0ea6d7ea1400e173d7'},\n",
       " {'answers': [{'answer_start': 223, 'text': '1,200 kilometres'}],\n",
       "  'question': 'How many kilometres do the Alps stretch?',\n",
       "  'id': '56f81f0ea6d7ea1400e173d8'},\n",
       " {'answers': [{'answer_start': 475, 'text': 'over tens of millions of years'}],\n",
       "  'question': 'How long has it taken for the Alps to form? ',\n",
       "  'id': '56f81f0ea6d7ea1400e173d9'},\n",
       " {'answers': [{'answer_start': 732, 'text': 'Mont Blanc'}],\n",
       "  'question': 'What is the highest mountain in the Alps?',\n",
       "  'id': '56f81f0ea6d7ea1400e173da'},\n",
       " {'answers': [{'answer_start': 936, 'text': 'the \"four-thousanders\"'}],\n",
       "  'question': 'The Alpine region is also known as what? ',\n",
       "  'id': '56f81f0ea6d7ea1400e173db'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_data['data'][91]['paragraphs'][0]['qas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_tokenizer = BertTokenizer.from_pretrained(\n",
    "    hf_model,\n",
    "    cache_dir=os.path.join(bert_cache, f'_{hf_model}-tokenizer')\n",
    ")\n",
    "save_path = os.path.join(bert_cache, f'{hf_model}-tokenizer')\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    slow_tokenizer.save_pretrained(save_path)\n",
    "    \n",
    "# Load the fast tokenizer from saved file\n",
    "tokenizer = BertWordPieceTokenizer(os.path.join(save_path, 'vocab.txt'),\n",
    "                                   lowercase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data for training\n",
    "Now we process the data so we can feed it later to the model.\n",
    "The idea is to replace the words (and some word parts) by numbers using the tokenizer above and organize the training data as a set of paragraphs and questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86136 training points created.\n",
      "CPU times: user 1min 1s, sys: 1.19 s, total: 1min 2s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_len = 384\n",
    "\n",
    "train_squad_examples = du.create_squad_examples(raw_train_data, max_len, tokenizer)\n",
    "x_train, y_train = du.create_inputs_targets(train_squad_examples)\n",
    "print(f\"{len(train_squad_examples)} training points created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The SquadExample objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_squad_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86136,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_squad_examples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataset_utils.SquadExample at 0x2aac4fee8ee0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 20299  # take the sample number 20299 out of the 86136 samples\n",
    "\n",
    "train_squad_examples[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['question', 'context', 'start_char_idx', 'answer_text', 'all_answers', 'max_len', 'skip', 'tokenizer', 'input_ids', 'token_type_ids', 'attention_mask', 'start_token_idx', 'end_token_idx', 'context_token_to_char'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_squad_examples[sample].__dict__.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86136, 384), (86136, 384), (86136, 384))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape, x_train[1].shape, x_train[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101,  1996, 13698,  1006,  1013,  1097, 14277,  2015,  1013,\n",
       "        1025,  3059,  1024,  2632,  8197,  1031,  1149,  2389,  8197,\n",
       "        1033,  1025,  2413,  1024,  2632, 10374,  1031,  2632,  2361,\n",
       "        1033,  1025,  2446,  1024,  2632, 11837,  1031,  1149, 29705,\n",
       "        2389,  9737,  1033,  1025, 18326,  1024,  2632,  5051,  1031,\n",
       "        1149,  2050, 23432, 14277, 29275,  1033,  1007,  2024,  1996,\n",
       "        3284,  1998,  2087,  4866,  3137,  2846,  2291,  2008,  3658,\n",
       "        4498,  1999,  2885,  1010, 10917,  3155,  1015,  1010,  3263,\n",
       "        3717,  1006,  9683,  2771,  1007,  2408,  2809, 10348,  3032,\n",
       "        1024,  5118,  1010,  2605,  1010,  2762,  1010,  3304,  1010,\n",
       "       26500,  1010, 14497,  1010, 10307,  1010,  1998,  5288,  1012,\n",
       "        1996, 16512,  4020,  2024,  3020,  1010,  1998,  1996, 24471,\n",
       "        9777,  2936,  1010,  2021,  2119,  4682,  6576,  1999,  4021,\n",
       "        1012,  1996,  4020,  2020,  2719,  2058, 15295,  1997,  8817,\n",
       "        1997,  2086,  2004,  1996,  3060,  1998, 23399,  8915, 28312,\n",
       "        2594,  7766, 17745,  1012,  6034,  2460,  7406,  3303,  2011,\n",
       "        1996,  2724,  4504,  1999,  3884, 25503,  5749,  4803,  2011,\n",
       "       21468,  1998, 12745,  2046,  2152,  3137, 11373,  2107,  2004,\n",
       "       18318, 18698,  1998,  1996,  3043,  9769,  1012, 18318, 18698,\n",
       "       14798,  1996,  2413,  1516,  3059,  3675,  1010,  1998,  2012,\n",
       "        1018,  1010,  6282,  2692,  1049,  1006,  2321,  1010,  6275,\n",
       "        2487,  3027,  1007,  2003,  1996,  3284,  3137,  1999,  1996,\n",
       "       13698,  1012,  1996, 10348,  2555,  2181,  3397,  2055,  1037,\n",
       "        3634, 11373,  3020,  2084,  1018,  1010,  2199,  1049,  1006,\n",
       "        2410,  1010, 13138,  3027,  1007,  1010,  2124,  2004,  1996,\n",
       "        1000,  2176,  1011,  4595,  2545,  1000,  1012,   102,  2129,\n",
       "        2146,  2038,  2009,  2579,  2005,  1996, 13698,  2000,  2433,\n",
       "        1029,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the alps ( / ælps / ; italian : alpi [ ˈalpi ] ; french : alpes [ alp ] ; german : alpen [ ˈʔalpm ] ; slovene : alpe [ ˈaːlpɛ ] ) are the highest and most extensive mountain range system that lies entirely in europe, stretching approximately 1, 200 kilometres ( 750 mi ) across eight alpine countries : austria, france, germany, italy, liechtenstein, monaco, slovenia, and switzerland. the caucasus mountains are higher, and the urals longer, but both lie partly in asia. the mountains were formed over tens of millions of years as the african and eurasian tectonic plates collided. extreme shortening caused by the event resulted in marine sedimentary rocks rising by thrusting and folding into high mountain peaks such as mont blanc and the matterhorn. mont blanc spans the french – italian border, and at 4, 810 m ( 15, 781 ft ) is the highest mountain in the alps. the alpine region area contains about a hundred peaks higher than 4, 000 m ( 13, 123 ft ), known as the \" four - thousanders \". how long has it taken for the alps to form?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A training sample is a paragraph plus a question\n",
    "#\n",
    "# The padding zeroes are discarded by the tokenizer's decoding\n",
    "tokenizer.decode(x_train[0][sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Token type ids](https://huggingface.co/transformers/glossary.html#token-type-ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `x_train[1][i]` is 1 for the elements that represent the question:\n",
    "x_train[1][sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how long has it taken for the alps to form?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `x_train[1][i]==1`, the question:\n",
    "question_encoded = x_train[0][sample][x_train[1][sample] == 1]\n",
    "tokenizer.decode(question_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Attention masks](https://huggingface.co/transformers/glossary.html#attention-mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `x_train[2][i]` has the value 1 for the elements that represent the text:\n",
    "x_train[2][sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the alps ( / ælps / ; italian : alpi [ ˈalpi ] ; french : alpes [ alp ] ; german : alpen [ ˈʔalpm ] ; slovene : alpe [ ˈaːlpɛ ] ) are the highest and most extensive mountain range system that lies entirely in europe, stretching approximately 1, 200 kilometres ( 750 mi ) across eight alpine countries : austria, france, germany, italy, liechtenstein, monaco, slovenia, and switzerland. the caucasus mountains are higher, and the urals longer, but both lie partly in asia. the mountains were formed over tens of millions of years as the african and eurasian tectonic plates collided. extreme shortening caused by the event resulted in marine sedimentary rocks rising by thrusting and folding into high mountain peaks such as mont blanc and the matterhorn. mont blanc spans the french – italian border, and at 4, 810 m ( 15, 781 ft ) is the highest mountain in the alps. the alpine region area contains about a hundred peaks higher than 4, 000 m ( 13, 123 ft ), known as the \" four - thousanders \". how long has it taken for the alps to form?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `x_train[1][i]==0` selects the context and `x_train[1][i]==1`, the question:\n",
    "context_encoded = x_train[0][sample][x_train[2][sample] == 1]\n",
    "tokenizer.decode(context_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86136,), (86136,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `y_train[0]` and `y_train[1]` are the possitions in the text where the answer starts and ends, respectively.\n",
    "y_train[0].shape, y_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * CONTEXT:                   \n",
      " The Alps (/ælps/; Italian: Alpi [ˈalpi]; French: Alpes [alp]; German: Alpen [ˈʔalpm̩]; Slovene: Alpe [ˈáːlpɛ]) are the highest and most extensive mountain range system that lies entirely in Europe, stretching approximately 1,200 kilometres (750 mi) across eight Alpine countries: Austria, France, Germany, Italy, Liechtenstein, Monaco, Slovenia, and Switzerland. The Caucasus Mountains are higher, and the Urals longer, but both lie partly in Asia. The mountains were formed over tens of millions of years as the African and Eurasian tectonic plates collided. Extreme shortening caused by the event resulted in marine sedimentary rocks rising by thrusting and folding into high mountain peaks such as Mont Blanc and the Matterhorn. Mont Blanc spans the French–Italian border, and at 4,810 m (15,781 ft) is the highest mountain in the Alps. The Alpine region area contains about a hundred peaks higher than 4,000 m (13,123 ft), known as the \"four-thousanders\".\n",
      "\n",
      " * QUESTION:                  \n",
      " How long has it taken for the Alps to form? \n",
      "\n",
      " * ANSWER (REFERENCE):        \n",
      " over tens of millions of years\n",
      "\n",
      " * ANSWER IN CONTEXT:         \n",
      " over tens of millions of years\n",
      "\n",
      "\n",
      " === TRAINING SAMPLE ===\n",
      "\n",
      " * CONTEXT & QUESTION:        \n",
      " the alps ( / ælps / ; italian : alpi [ ˈalpi ] ; french : alpes [ alp ] ; german : alpen [ ˈʔalpm ] ; slovene : alpe [ ˈaːlpɛ ] ) are the highest and most extensive mountain range system that lies entirely in europe, stretching approximately 1, 200 kilometres ( 750 mi ) across eight alpine countries : austria, france, germany, italy, liechtenstein, monaco, slovenia, and switzerland. the caucasus mountains are higher, and the urals longer, but both lie partly in asia. the mountains were formed over tens of millions of years as the african and eurasian tectonic plates collided. extreme shortening caused by the event resulted in marine sedimentary rocks rising by thrusting and folding into high mountain peaks such as mont blanc and the matterhorn. mont blanc spans the french – italian border, and at 4, 810 m ( 15, 781 ft ) is the highest mountain in the alps. the alpine region area contains about a hundred peaks higher than 4, 000 m ( 13, 123 ft ), known as the \" four - thousanders \". how long has it taken for the alps to form?\n",
      "\n",
      " * POSITION IN CONTEXT:       \n",
      " (122, 127)\n"
     ]
    }
   ],
   "source": [
    "print('\\n * CONTEXT:                   \\n', train_squad_examples[sample].context)\n",
    "print('\\n * QUESTION:                  \\n', train_squad_examples[sample].question)\n",
    "print('\\n * ANSWER (REFERENCE):        \\n', train_squad_examples[sample].answer_text)\n",
    "\n",
    "print('\\n * ANSWER IN CONTEXT:         \\n', tokenizer.decode(x_train[0][sample][ y_train[0][sample]:y_train[1][sample]+1 ]))\n",
    "\n",
    "print('\\n\\n === TRAINING SAMPLE ===')\n",
    "print('\\n * CONTEXT & QUESTION:        \\n', tokenizer.decode(x_train[0][sample]))\n",
    "print('\\n * POSITION IN CONTEXT:       \\n', (y_train[0][sample], y_train[1][sample]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepspeed",
   "language": "python",
   "name": "deepspeed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
